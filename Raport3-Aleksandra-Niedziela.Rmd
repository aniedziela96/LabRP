---
title: "Raport 3"
author: "Aleksandra Niedziela"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    dev: cairo_pdf
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(ggplot2)
```

# Problem kolekcjonera kuponów

Aby wygrać w konkursie potrzebujemy $n$ kuponów. Interesuje nas liczba pudełek $X_n$, po których zakupie otrzymamy nagrodę. Liczba $X_n$ to zmienna losowa. 
Przyjmijmy, że mamy już $k - 1$ kuponów, niech $X_{n,k}$ będzie liczbą pudełek, które musimy kupić, aby posiadać $k$ kuponów.

- $X_{n,k}$ to zmienna losowa, o rozkładzie geometrycznym z parametrem $\frac{n - k + 1}{n}$ 
- $X_n = X_{n, 1} + X_{n, 2} + \ldots + X_{n, n} = \sum_{k = 1}^{n}X_{n,k}$

Policzmy teraz wartość oczekiwaną zmiennej $X_n$

$$E[X_n] = \sum_{k = 1}^{n}\frac{n}{n - k + 1} = n \sum_{k = 0}^{n - 1}\frac{1}{n - k} = n \sum_{k = 1}^{n}\frac{1}{k}$$

## Symulacja 

Przeprowadźmy teraz symulację, za pomocą poniższej funckji

```{r teoretical_boxes, echo = FALSE}
theoretical_boxes <- function(n){
  return(n * sum(1/(1:n)))
}

```

```{r boxes_function, echo = TRUE}
boxes <- function(n){
  coupons <- 1:n
  aquired_coupons <- numeric(n)
  prize <- sum(1:n)
  a <- 0

  while (sum(aquired_coupons) != prize){
    coupon <- sample(1:n, 1)
    aquired_coupons[coupon] = coupon
    a <- a + 1
  }
  return(a)
}
```

```{r symulation_1, echo = FALSE}
n_values <- c(10, 25, 100, 500, 1000)
teoretical_boxes_number <- numeric(5)
experimental_boxel_number <- numeric(5)
for (i in 1:5) {
  n <- n_values[i]
  teoretical_boxes_number[i] <- theoretical_boxes(n)
  experimental_boxel_number[i] <- boxes(n)
}

data_1 <- data.frame(n_values, 
                     teoretical_boxes_number,
                     experimental_boxel_number)
```

Wyniki możemy przedstawić w tabeli: 

```{r table_1, echo = FALSE}
kable(head(data_1[, 1:3]),"latex", 
      digits = 0, 
      caption = "Porównanie wartości eksperymentalnych i teoretycznych",
      col.names = c("ilość kuponów",
                    "Wartość teoretyczna",
                    "Wartość eksperymentalna")) %>%
   kable_styling(font_size = 12, 
                 latex_options = "HOLD_position", 
                 position = "center")

```

Spójrzmy teraz na wykres pokazujący średnią liczbę pudełek (10 prób), po których zakupieniu zbierzemy wszystkie kupony

```{r symulation_2, echo = FALSE, cache = TRUE}
n_values <- 1:1000
experimental_boxes_number <- numeric(1000)
for (i in 1:1000) {
  boxes_sum <- 0
  for (j in 1:10) {
    n <- n_values[i]
    boxes_sum <- boxes_sum + boxes(n)
  }
  experimental_boxes_number[i] <- boxes_sum / 10
}

log_n <- n_values * log(n_values)
log_n_plus_1 <- n_values * (log(n_values) + 1)

data_2 <- data.frame(n_values, 
                     experimental_boxes_number,
                     log_n,
                     log_n_plus_1)

```

```{r plot_1, eval=TRUE, echo=FALSE, fig.height=4.5, fig.align='center'}
ggplot(data_2, aes(x = n_values)) +
  geom_point(aes(y = experimental_boxes_number), 
             size = 0.5) +
  geom_line(aes(y = log_n), 
            color = "blue", 
            linewidth = 1) +
  geom_line(aes(y = log_n_plus_1),
            color = "red", 
            linewidth = 1) +
  labs(x = "Liczba kuponów", y = "Liczba pudełek potrzebna do zebrania kuponów")
```

Czerwona i niebieska linia oznaczają ograniczenia wynikające z faktu:

$$\ln(n) < \sum_{k = 1}^{n}\frac{1}{k} < \ln(n) + 1$$
$$ n \cdot \ln(n) < E[X_n] < n \cdot (\ln(n) + 1)$$

# Nierówność Markowa 

Niech X będzie zmienną losową, która przyjmuje jedynie nieujemne wartości. Wtedy dla wszystkich a > 0,

$$P(X \ge a) \le \frac{E[X]}{a}$$

Korzystając z nierówności Markowa możemy oszacować prawdopodobieństwo uzyskania co najmniej $\frac{3n}{4}$ orłów w $n$ rzutach monetą. Przyjmijmy za zmienną losową $X_n$ liczbę wyrzuconych orłów w $n$ rzutach. Widzimy, iż jest to schemat Bernoulliego, gdzie prawdopodobieństwo sukcesu (wyrzucenia orła) wynosi $\frac{1}{2}$, stąd mamy:

$$E[X_n] = \frac{n}{2}$$

Teraz z nierówności Markowa otrzymujemy:

$$P(X_n \ge \frac{3n}{4}) \le \frac{\frac{n}{2}}{\frac{3n}{4}} = \frac{2}{3}$$

Możemy wyliczyć dokładne prawdopodobieństwa dla ustalonej ilości rzutów, a następnie zauważyć, że za każdym razem są one ograniczone przez $\frac{2}{3}$
 
```{r symulation_3, eval=TRUE, echo=FALSE}
n_values <- c(4, 10, 20, 50, 100)
prob <- c()
for (i in 1:5){
  n <- n_values[i]
  prob <- c(prob, pbinom((0.75 * n) - 1, n, 0.5, lower.tail = FALSE))
}

data_3 <- data.frame(n_values, prob)

kable(head(data_3[, 1:2]),"latex", 
      digits = 8, 
      col.names = c("n",
                    "prawdopodobieństwo wyrzucenia 3n/4 orłów")) %>%
   kable_styling(font_size = 12, 
                 latex_options = "HOLD_position", 
                 position = "center", 
                 )
```

Zobaczmy teraz jak nierówność Markowa sprawdza się dla rozkładu normalnego, dla różnych wartości $a$. Wiemy, że dla rozkładu normalnego $N(\mu, \sigma)$, $E[X] = \mu$. Weźmy $\mu$ = 2 oraz $\sigma$ = 1. 

```{r plot_2, eval=TRUE, echo=FALSE, fig.height=4, fig.align='center'}
a <- seq(0, 4, 0.01)
prob <- pnorm(a, mean = 2, sd = 1, lower.tail = FALSE)
markow <- 2/a

plot(a, prob, ylim = c(0,1.1), type = "l", lwd = 2,
     xlab = " ",
     ylab = " ",
     main = "Porównanie oszacowania, z wartością dokładną") 
lines(a, markow, type = "l", lwd = 2, col = "red")
legend(2.75, 1.01, legend = c("Wartość dokładna", "Markow"), 
       col = c("black", "red"),
       lty = 1,
       cex = 0.75)
```
 
# Nierówność Czebyszewa 

Dla dowolnego $a > 0$ mamy:

$$P(|X - E[X]| \ge a) \le \frac{Var[X]}{a^2}$$

Korzystając z powyższej nierówności możemy ponownie oszacować prawdopodobieństwo wyrzucenia $\frac{3n}{4}$ orłów w $n$ rzutach symetryczną monetą. Wiemy, że $Var[X] = np(1-p)$. Mamy:

$$P(|X - E[X]| \ge a) = P(X \ge a + E[X]) + P(X \le -a + E[X])$$

Chcemy, aby $a + E[X] = \frac{3n}{4}$, więc $a = \frac{n}{4}$. Ponieważ patrzymy tutaj na rozkład Bernoulliego, to mamy: 
$$P(X \ge a + E[X]) + P(X \le -a + E[X]) = 2P(X \ge \frac{3n}{4}) \le \frac{Var[X]}{(\frac{n}{4})^2} = \frac{n \cdot 0.5 \cdot 0.5}{\frac{n^2}{16}} = \frac{4}{n}$$
Stąd prawdopodobieństwo wyrzucenia $\frac{3n}{4}$ orłów możemy oszacować przez $\frac{2}{n}$

W przeciwieństwie do ograniczenia wynikającego z nierówności Markowa wynik jest zależny od ilości powtórzeń eksperymentu.

Spójrzmy teraz na wykres, gdzie dla rozkładu normalnego porównamy oszacowanie z wartością dokładną ogona dystrybuanty. Dla rozkładu normalnego mamy $Var[X] = \sigma^2$. 

```{r plot_3, eval=TRUE, echo=FALSE, fig.height=4, fig.align='center'}
mu <- 2
s <- 1

a <- seq(0, 4, 0.01)
prob <- pnorm(a + mu, mean = mu, sd = s, lower.tail = FALSE) + 
  pnorm(mu - a, mean = mu, sd = s)
czebyszew <- s/(a^2)


plot(a, prob, ylim = c(0,1.1), type = "l", lwd = 2,
     xlab = " ",
     ylab = " ",
     main = "Porównanie oszacowania, z wartością dokładną") 
lines(a, czebyszew, type = "l", lwd = 2, col = "red")
legend(2.5, 1, legend = c("Wartość dokładna", "Czebyszew"), 
       col = c("black", "red"),
       lty = 1,
       cex = 0.75)
  
```

Korzystatjąc z nierówności Markowa, możemy oszacować wartość $P(X \ge 2nH_n)$, gdzie $X$ to zmienna losowa oznaczająca ilość pudełek, które musimy kupić by wygrać nagrodę (problem kolekcjonera kuponów), natomiast $H_n = \sum_{i = 1}^{n}\frac{1}{i}$. Mamy $E[X] = n \sum_{i = 1}^{n}\frac{1}{i}$

$$ P(X \ge 2nH_n) \le \frac{E[X]}{a} = \frac{n \sum_{i = 1}^{n}\frac{1}{i}}{2n \sum_{i = 1}^{n}\frac{1}{i}} = \frac{1}{2}$$

Teraz korzystając z nierówności Czebyszewa oszacujmy $P(|X - nH_n| \ge nH_n)$
Aby policzyć $Var[X]$ skorzystamy z faktu, iż $Var[X] = \sum_{i = 1}^{n}Var[X_i]$. Wiemy, iż zmienne $X_i$ mają rozkład geometryczny, stąd $Var[X_i] = \frac{(1-p)}{p^2}$

$$ P(|X - nH_n| \ge nH_n) \le \frac{Var[X]}{a^2} = \frac{\sum_{i = 1}^{n}Var[X_i]}{(nH_n)^2} \le \frac{\pi^2n^2}{6n^2H_n^2} \le \frac{\pi^2}{6 (\ln n)^2}$$

Porównajmy otrzymane oszacowania

```{r plot_4, eval=TRUE, echo=FALSE, fig.height=4, fig.align='center'}

n <- 2:1000
markow <- rep(0.5, 999)
czebyszew <- pi^2/(6*(log(n)))


plot(n, markow, ylim = c(0,1.1), type = "l", lwd = 2,
     xlab = " ",
     ylab = " ",
     main = "Porównanie oszacowania nierównością Markowa i Czebyszewa") 
lines(n, czebyszew, type = "l", lwd = 2, col = "red")
legend(650, 1, legend = c("Markow", "Czebyszew"), 
       col = c("black", "red"),
       lty = 1,
       cex = 0.75)
  
```

Widzimy, że dla małych wartości $n$ lepsze oszacowanie daje nam nierówność Markowa, natomiast wraz ze wzrostem $n$ nierówność Czebyszewa daje dokładniejsze przybliżenia. 

# Średnia, dyspersja, mediana 

Jeśli X jest zmienną losową o średniej $\mu$ odchyleniu standardowym $\sigma$ i medianie $m$ wtedy:

$$|\mu - m| \le \sigma$$

Aby sprawdzić, czy nierówność ta jest prawdziwa dla estymatorów mediany, średniej i odchylenia przeprowadźmy prostą symulację. Wybierzmy próbę 200 mężczyzn z populacji i przyjrzyjmy się estymatorom. Losujemy wartości z rozkładu normalnegoz parametrami $\mu$ = 178, $\sigma$ = 5, jako że tak możemy modelować zmienną losową opisującą wzrost w populacji. 

```{r symulation_4, echo = FALSE}
men <- round(rnorm(200, mean = 178, sd = 5))
mean_est <- mean(men)
median_est <- median(men)
sd_est <- sd(men) 
dif <- abs(mean_est - median_est)
```

Otrzymujemy: 

- $\mu$ = `r sprintf(mean_est, fmt = '%#.3f')`
- $m$ = `r sprintf(median_est, fmt = '%#.3f')`
- $\sigma$ = `r sprintf(sd_est, fmt = '%#.3f')`

$$|\mu - m| = `r sprintf(dif, fmt = '%#.2f')` \le `r sprintf(sd_est, fmt = '%#.2f')` = \sigma$$

